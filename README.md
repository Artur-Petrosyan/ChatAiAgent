# Ollama LangGraph Agent

A simple AI agent built with LangGraph.js and Ollama with a React + Vite web interface.

## ğŸš€ Quick Start

### Requirements

- Node.js 18+
- Ollama installed and running locally
- Ollama model (e.g., mistral)

### Installation

```bash
# Install dependencies
npm install

# Run in development mode (server and client simultaneously)
npm run dev
```

The application will be available at:
- Frontend: http://localhost:3000
- Backend API: http://localhost:3001

### Ollama Setup

Make sure Ollama is running:

```bash
# Check Ollama status
curl http://localhost:11434/api/tags
```

To change the model, edit `src/agent/nodes.ts`:

```typescript
const model = new ChatOllama({
  model: "your-model", // Change here
});
```

## ğŸ“ Project Structure

```
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agent/          # LangGraph agent logic
â”‚   â”‚   â”œâ”€â”€ state.ts     # State definition
â”‚   â”‚   â”œâ”€â”€ nodes.ts     # Graph nodes
â”‚   â”‚   â””â”€â”€ graph.ts     # Graph assembly
â”‚   â”œâ”€â”€ server/          # Express server
â”‚   â”‚   â””â”€â”€ index.ts     # API endpoints
â”‚   â”œâ”€â”€ App.tsx          # React component
â”‚   â””â”€â”€ main.tsx         # Entry point
â”œâ”€â”€ package.json
â””â”€â”€ vite.config.ts
```

## ğŸ› ï¸ Usage

1. Run `npm run dev`
2. Open http://localhost:3000
3. Ask the agent a question in the interface

## ğŸ“ API

### POST /api/chat

Send a message to the agent.

**Request:**
```json
{
  "message": "Hello, how are you?"
}
```

**Response:**
```json
{
  "response": "Hello! I'm doing great, thank you!",
  "llmCalls": 1,
  "sessionId": "session-id"
}
```

### GET /api/health

Check server status.

## ğŸ”§ Development

- `npm run dev` - run in development mode
- `npm run build` - build for production
- `npm run preview` - preview production build

## ğŸ“š Technologies

- **LangGraph.js** - AI agent orchestration
- **Ollama** - local LLM
- **React** - UI framework
- **Vite** - build tool
- **Express** - backend server
- **TypeScript** - type safety

---

# Ollama LangGraph Agent

ĞŸÑ€Ğ¾ÑÑ‚Ğ¾Ğ¹ AI-Ğ°Ğ³ĞµĞ½Ñ‚ Ğ½Ğ° Ğ±Ğ°Ğ·Ğµ LangGraph.js Ğ¸ Ollama Ñ Ğ²ĞµĞ±-Ğ¸Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹ÑĞ¾Ğ¼ Ğ½Ğ° React + Vite.

## ğŸš€ Ğ‘Ñ‹ÑÑ‚Ñ€Ñ‹Ğ¹ ÑÑ‚Ğ°Ñ€Ñ‚

### Ğ¢Ñ€ĞµĞ±Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ

- Node.js 18+
- Ollama ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½ Ğ¸ Ğ·Ğ°Ğ¿ÑƒÑ‰ĞµĞ½ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾
- ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ollama (Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€, mistral)

### Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ°

```bash
# Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ĞµĞ¹
npm install

# Ğ—Ğ°Ğ¿ÑƒÑĞº Ğ² Ñ€ĞµĞ¶Ğ¸Ğ¼Ğµ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ (Ğ¾Ğ´Ğ½Ğ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾ ÑĞµÑ€Ğ²ĞµÑ€ Ğ¸ ĞºĞ»Ğ¸ĞµĞ½Ñ‚)
npm run dev
```

ĞŸÑ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ Ğ±ÑƒĞ´ĞµÑ‚ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ¾:
- Frontend: http://localhost:3000
- Backend API: http://localhost:3001

### ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ollama

Ğ£Ğ±ĞµĞ´Ğ¸Ñ‚ĞµÑÑŒ, Ñ‡Ñ‚Ğ¾ Ollama Ğ·Ğ°Ğ¿ÑƒÑ‰ĞµĞ½:

```bash
# ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ÑÑ‚Ğ°Ñ‚ÑƒÑĞ° Ollama
curl http://localhost:11434/api/tags
```

Ğ•ÑĞ»Ğ¸ Ğ½ÑƒĞ¶Ğ½Ğ¾ Ğ¸Ğ·Ğ¼ĞµĞ½Ğ¸Ñ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ, Ğ¾Ñ‚Ñ€ĞµĞ´Ğ°ĞºÑ‚Ğ¸Ñ€ÑƒĞ¹Ñ‚Ğµ `src/agent/nodes.ts`:

```typescript
const model = new ChatOllama({
  model: "Ğ²Ğ°ÑˆĞ°-Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ", // Ğ˜Ğ·Ğ¼ĞµĞ½Ğ¸Ñ‚Ğµ Ğ·Ğ´ĞµÑÑŒ
});
```

## ğŸ“ Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ° Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°

```
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agent/          # Ğ›Ğ¾Ğ³Ğ¸ĞºĞ° LangGraph Ğ°Ğ³ĞµĞ½Ñ‚Ğ°
â”‚   â”‚   â”œâ”€â”€ state.ts     # ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ñ
â”‚   â”‚   â”œâ”€â”€ nodes.ts     # Ğ£Ğ·Ğ»Ñ‹ Ğ³Ñ€Ğ°Ñ„Ğ°
â”‚   â”‚   â””â”€â”€ graph.ts     # Ğ¡Ğ±Ğ¾Ñ€ĞºĞ° Ğ³Ñ€Ğ°Ñ„Ğ°
â”‚   â”œâ”€â”€ server/          # Express ÑĞµÑ€Ğ²ĞµÑ€
â”‚   â”‚   â””â”€â”€ index.ts     # API endpoints
â”‚   â”œâ”€â”€ App.tsx          # React ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚
â”‚   â””â”€â”€ main.tsx         # Ğ¢Ğ¾Ñ‡ĞºĞ° Ğ²Ñ…Ğ¾Ğ´Ğ°
â”œâ”€â”€ package.json
â””â”€â”€ vite.config.ts
```

## ğŸ› ï¸ Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ

1. Ğ—Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚Ğµ `npm run dev`
2. ĞÑ‚ĞºÑ€Ğ¾Ğ¹Ñ‚Ğµ http://localhost:3000
3. Ğ—Ğ°Ğ´Ğ°Ğ¹Ñ‚Ğµ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ Ğ°Ğ³ĞµĞ½Ñ‚Ñƒ Ğ² Ğ¸Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹ÑĞµ

## ğŸ“ API

### POST /api/chat

ĞÑ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ° ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ Ğ°Ğ³ĞµĞ½Ñ‚Ñƒ.

**Ğ—Ğ°Ğ¿Ñ€Ğ¾Ñ:**
```json
{
  "message": "ĞŸÑ€Ğ¸Ğ²ĞµÑ‚, ĞºĞ°Ğº Ğ´ĞµĞ»Ğ°?"
}
```

**ĞÑ‚Ğ²ĞµÑ‚:**
```json
{
  "response": "ĞŸÑ€Ğ¸Ğ²ĞµÑ‚! Ğ£ Ğ¼ĞµĞ½Ñ Ğ²ÑÑ‘ Ğ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ½Ğ¾, ÑĞ¿Ğ°ÑĞ¸Ğ±Ğ¾!",
  "llmCalls": 1,
  "sessionId": "session-id"
}
```

### GET /api/health

ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ÑÑ‚Ğ°Ñ‚ÑƒÑĞ° ÑĞµÑ€Ğ²ĞµÑ€Ğ°.

## ğŸ”§ Ğ Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°

- `npm run dev` - Ğ·Ğ°Ğ¿ÑƒÑĞº Ğ² Ñ€ĞµĞ¶Ğ¸Ğ¼Ğµ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸
- `npm run build` - ÑĞ±Ğ¾Ñ€ĞºĞ° Ğ´Ğ»Ñ production
- `npm run preview` - Ğ¿Ñ€ĞµĞ´Ğ¿Ñ€Ğ¾ÑĞ¼Ğ¾Ñ‚Ñ€ production ÑĞ±Ğ¾Ñ€ĞºĞ¸

## ğŸ“š Ğ¢ĞµÑ…Ğ½Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ğ¸

- **LangGraph.js** - Ğ¾Ñ€ĞºĞµÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ AI-Ğ°Ğ³ĞµĞ½Ñ‚Ğ°
- **Ollama** - Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ°Ñ LLM
- **React** - UI Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€Ğº
- **Vite** - ÑĞ±Ğ¾Ñ€Ñ‰Ğ¸Ğº
- **Express** - backend ÑĞµÑ€Ğ²ĞµÑ€
- **TypeScript** - Ñ‚Ğ¸Ğ¿Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ
